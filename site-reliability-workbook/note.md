# [Site Reliability Workbook](https://www.oreilly.co.jp/books/9784873119137/)

English version is available online: https://sre.google/books/

## １章：SRE と DevOps の関係

- DevOps 哲学の要素：サイロの抑制、アクシデントの受容、変化は小さく頻繁に起こす。
- `class SRE implements interface DevOps`: SRE は DevOps が掲げる哲学の一部を実施したものといえ、「DevOps エンジニア」よりも明確な仕事やロールの定義と言える
- SRE を定義する原理
  - 運用はソフトウェアの問題
  - サービスレベル目標による管理
  - トイルの最小化のための作業
  - 今年のジョブの自動化
  - 失敗のコストの削減による速度の向上
  - 開発者との共有オーナーシップ
  - 役割や仕事の肩書きに関わらず同じツールを使うこと
- DevOps と SRE は多くの領域で共通点がある。一方でDevOps はサービスの運用方法についてはあまり言及していない。SRE はサービス（エンドユーザー指向）で、システムを効率的に動作させるという問題も取り扱う
- DevOps と SRE を浸透させるための設計
  - 狭く、硬直したインセンティブは成功を妨げる
  - 修正は自分で行う、他の誰かを責めない
  - 信頼性に関する作業を特化した役割として考える
  - 「やるかどうか」は「いつやるか」に置き換えられる

## 第１部：基礎

### ２章：SLO の実装

- SRE の日々のタスクやプロジェクトは、SLO によって駆動される。SLO は、どのエンジニアリング作業を優先するかの決定を助けるツールと言える。
- エラーバジェットベースのアプローチを採用するための要件
  - SLO があり、それがプロダクトに適していると組織内の全てのステークホルダーが承認していること
  - サービスが SLO を満たしていることを保証する責任を負う人々が、通常の状況下でこの SLO を満たせると同意したこと
  - 意思決定と優先順位付けにエラーバジェットを利用することに組織がコミットしたこと。そのコミットメントがエラーバジェットのポリシーとして公式のものとなっていること
  - SLO を改定するためのプロセスが存在すること
- SLO を形成するための最初のステップ：SLO が何をカバーすべきなのかを話す。究極的にはユーザーの満足。SLO が満たされていれば、ほとんどのユーザーは（サービス自体の有用性を認めているとして）サービスには満足しているはず。
- SLO を決めたら、機能リリースの速度と信頼性とのトレードオフを決める権限を持っている組織内の人物に、その責任者になってもらう。CTO や PdM など。
- SLI のおすすめ：良いイベントの数とイベントの総数の比で扱うこと
- SLI はサービスの種類（リクエスト駆動、パイプライン、ストレージなど）ごとに、それぞれ一般的なものが存在する。
- SLO を評価するウィンドウを短くすれば、判断をより早く下せるようになる。期間を長く取れば、（工数のかかる）より戦略的な判断に役立つ。Google のおすすめは4週間。
- ステークホルダーとの同意
  - PdM：SLO の違反は、ユーザーにとって許容できないパフォーマンスであると同意する。
  - 開発メンバー：エラーバジェットが尽きたら、バジェットが回復するまでリスク軽減策を講じることに同意する。
  - プロダクション環境に責任を持つチーム：大変な労力、過剰なトイルやバーンアウトなく SLO を守れる
- SLO の維持や信頼性の回復が大変なら、SLO を緩和することも検討できる。一方でエラーバジェットに抵触していないのにユーザー体験が悪化すると感じるなら、その SLO は緩すぎるかもしれない。
- SLO とエラーバジェットポリシー（エラーバジェットが消費された際にどんなアクションを取るかの決まり）は、明示的なドキュメントとしてステークホルダーで合意する必要がある。
- クリティカルユーザージャーニーを考えることで、ユーザー体験に沿った SLO を検討できる。
- SLO はスタック中のさまざまなコンポーネント間の信頼性の要求の調整と実装にも役立つ

### ３章：SLO のケーススタディ

- Evertnote のケースでは、月次 SLO パフォーマンスレビューに加えて、６ヶ月ごとに SLO レビューサイクルを設定した
- SLO に基けば、例えば顧客に影響のあるリリースを分散するなどの意思決定ができる
- リリースサイクルと SLO のタイムウィンドウを合わせるのはありかも
- Google CRE は Evernote のチームに対して、単なる相談窓口以上にかなり具体的に連携していたっぽい？
- マイクロサービスにおける「自由と責任の文化」：好きな時にコードをプッシュしてよいが、自分達のサービスの運用にも責任を持つ。
- SLO 文化構築のための戦略：共通の言語化、普及活動（説明会やワークショップ）、自動化（メトリクス収集など）、SLO 維持へのインセンティブなど
- Google SRE の４大シグナル：トラフィック量、レイテンシ、エラー、利用率
- The Home Depot における SLO 普及のための用語：VALET：Volume (traffic), Availability, Latency, Erros, Tickets
- SLO にアクセスできるチャットボット面白そう
- SLO の履歴をストレージに保持しておいて、定期的にクエリしてレポートを作れるようにしておくの大事そう
- バッチアプリケーションにおける VALET の適用：Volume（処理されたレコード量）、Availability（ある時間までにジョブが完了した頻度）、Latency（ジョブ実行にかかった時間）、エラー（処理に失敗したレコード数）、チケット（オペレータが再実行など手動で対応したジョブの数）
- サービスの SLO は、ビジネス上でそのサービスを所有しているプロダクトマネージャーなどが、ビジネス上の要求に基づいて設定すべき
- 新しいプロセスを大企業に導入するには、優れた戦略、幹部の同意、強力な普及活動、採択を容易にするパターン、そして忍耐が必要

### ４章：モニタリング

- 理想的には、イベントやリソース消費に対して保持するメトリクスは単調増加するカウンターであるべき。カウンターを使えば、モニタリングシステムは時間の経過に対してウィンドウ関数を計算できる
- Datadog IaC の勉強したい。SLO とかも
- Istio のようなサービスメッシュツールや、OpenCensus などのライブラリを使うと、複数のサービスで一貫した基本のメトリクス群をエクスポートできる
- 現代的な設計では、データの収集と評価、長期間にわたる時系列データのストレージ、アラートの集約、ダッシュボード化は分離されることが多い
- 以下のメトリクスは、プロダクションの問題を調査できる妥当なモニタリングを提供する
  - 意図された変更：バイナリのバージョン、コマンドラインフラグ、設定データのバージョン
  - 依存性：依存対象サービスからのレスポンスのバイトサイズ、レスポンスコード、レイテンシなど
  - 飽和：サービスが依存するリソースの利用状況、RAM やディスク、CPU のクオータなど
  - ユーザートラフィックの状態：設定したステータスコード、レート制限やクオータ制限が発生したリクエスト
- 理想的には、アラートに関わるメトリクスはシステムに問題が生じたときだけ劇的に変化するべき。一方でデバッグ用のメトリクスは問題の原因となる可能性があるシステムの側面を指摘する。
- ポストモーテムを書く際には、どういったメトリクスがあれば問題を診断に役立ったかも考えるとよい
- 感想：アラートのロジックのテスト、入れたい、、

### ５章：SLO に基づくアラート

### ６章：トイルの撲滅

- SRE の最適化はシステムのパフォーマンスだけでなく、自身の時間の使い方に関してもまた重要
- トイルの特徴：手作業、繰り返し、自動化可能、非戦略的、持続的な価値の欠如、発生源と同じ速度で増加
- トイルは概して重要な思案や創造性の発揮に使われた時間ではない
- 自動化によるトイルの削減の理論と現実の画像辛すぎ
- トイル対応の負荷を測る際には、必ずコンテキストスイッチの負荷を考慮する
- トイルの分類学：ビジネスプロセス、プロダクションへの割り込み、リリースの世話、マイグレーション、コストエンジニアリングとキャパシティプランニング、不明瞭なアーキテクチャのトラブルシューティング
- 社内の技術やツールキットの一様化を進めることで、トイルを減らすことができる
- 自動化が管理者レベルの力を振るう場合には、防御的なソフトウェアがとても重要。全てのアクションは実行前に安全性が評価されるべき
- ケーススタディ: Google データセンターのセットワーキング、Google 内のビジネスプロセスをサポートする、特化型ハードウェアのチーム。
- データセンターでの物理デバイスの運用タスクはトイルになりやすそう
- 柔軟でない自動化に依存するシステムは、変化に対して脆くなる。気をつけよう
- トイルの削減に向けた自動化開発に着手する場合もも、エラーバジェットに基づいた判断が可能。
- 新規顧客データの受け入れに伴うビジネスプロセスもトイルと言えるかも
- ディレクトリシステムの退役、移行はトイル削減の取り組みの中ではかなり大規模で、体力と根気と計画力が必要そう
- トイルの多いビジネスプロセスに対して、定期的に疑問を投げかけけることには大きな価値がある。トイル削減に着手する際には、ユーザーの分析とビジネス上のメリットを適切に把握する必要がある。
- 「カーテンの裏にエンジニア」アプローチ：自動化ソリューションがユーザーのリクエストが処理できない場合などに、別途 SRE が手作業で対応すること
- トイルを特定したら、メトリクス、費用対効果分析、リスク評価、イテレーティブ開発を活用して、いつトイル削減をするのが理にかなっているかを判断することが重要


### ７章：単純さ

## 第２部：実践

- SRE チームの業務は、運用業務とプロジェクト業務に大別される
  - 運用業務：オーバーヘッド、オンコール担当、ポストモーテム、その他割り込み。これらの一部がトイルといえる。またドキュメンテーションは各業務に内包されるべきである。
  - プロジェクト業務：上記をより持続可能にするためのプロジェクト。特定の期間と目的、成果物を持つ試み。
- 運用業務で浮上した課題を適切にプロジェクト業務に移行し、システムの効率性を高め、スケーラビリティと信頼性を高めるために戦略を練る必要がある。

### ８章：オンコール

- オンコールはその構成やロジスティクスだけでなく、インセンティブと人間性も重要な役割を果たす
- 新規 SRE チーム立ち上げ時に、Google で実施したトレーニング
  - プロダクションジョブの管理
  - デバッグ情報の理解
  - クラスタからのトラフィックのドレイン
  - 問題あるソフトウェアのプッシュのロールバック
  - 望ましくないトラフィックのブロックまたはレート制限
  - 追加のサーバーキャパシティの立ち上げ
  - モニタリングシステムの利用方法（アラートとダッシュボードのため）
  - アーキテクチャ、さまざまなコンポーネント、サービスの依存関係の記述
- オンコールのプレイブック：アラートの重大性とインパクト、デバッグにおける水晶事項と、完全な解決のために取れるアクションなどを含む→作りたい
- 将来のチームメンバーの交代や追加を見越して、サービスのアーキテクチャ図や基本的なトレーニングチェックリストを練習課題として残せると良い→これも作りたい
- ページングイベントのトリアージ：P1（即時対応、SLO にインパクトがある）、P2（翌業務日に対応、顧客への影響はない）、P3（情報のみのイベント）
- ページングイベントにはそれぞれ適切なレスポンスタイムがある。収益にインパクトがあるインシデントには数分以内にレスポンスする必要があるが、緊急性の薄いものは、チケット化して業務時間内の対応で良い。ページングの必要性を検証することは重要
- ページャーの負荷は、特にプロダクション環境、アラートの設定、人間が関わるプロセスによって影響される
- プロダクションで見つかったバグに対して、「そうすればプロダクション以前にこのバグを検出できたか」を考える
- 新しいバグがプロダクションにリリースされてしまう頻度を管理するために、エラーバジェットは有用といえる。エラーバジェットが消費されたら、システムの安定化とページの頻度の低下に集中する
- アラートの原因の特定の遅れは、リリースの細分化や緊急レスポンスの訓練によって対応できる
- バグによる症状の緩和の遅れは、変更のロールバックや機能の分離を利用することで対応できる
- 新しいアラートは注意深くレビューされる必要がある。それぞれのアラートには、対応するエントリーがプレイブックにあるべきである。
- 全てのページングについて、厳格にフォローアップを行い、将来のシステム改善につなげることが重要となる
- フォローアップの例：このバグの再発を抑えるには？どんなテストがあればリリース前にバグを検知できた？どんな情報アラートなら、影響が深刻になる前に検知できた？など
- Google のオンコール担当は、通常オンコールのシフト中にはプロジェクトの作業をせず、代わりにシステムの健全性を向上させるバグの作業をする
- アラートとバグの対応を Jira や Issue Tracker と連携して構築し、アセット化するの良さそう。
- 人数が少ない場合のオンコールシフトの運用がよくわからない。夜間オンコールのメンバーはその時間を普通の業務時間としてバグのドキュメンテーションなども行う？
- オンコールシフトの調整や、柔軟性を原則として設計するのが良い

### ９章：インシデント管理

- インシデント管理の前提：インシデントに対して構造化された方法で対応する
- インシデント対応の基本原則：明確な指示系統の管理、明確に規定された役割の割り当て、作業と並行してデバッグと緩和の作業記録をつける、インシデントの宣言を早期に頻繁に行う
- インシデントにおける主な役割：インシデント指揮者（IC：Incident Comannder）、コミュニケーションリード（CL）、実作業リード（OL）。CL, OL は IC に報告する。
- IC は 3Cs（作業の調整、関係者とのコミュニケーション、対応に対するコントロール）のために行動する。
- CL はインシデント対応チームの公式の窓口として情報のアップデートや問い合わせの管理を行う。OL はインシデントによる影響を緩和または解決するための作業を行う
- Google Home のケーススタディ面白い。カナリアリリースが前提になっていて、まずリリースのロールバックができるの大事。
- インシデントを早期に宣言することで、クライアント・サーバー開発者間の誤解が避けられる、根本原因の特定とインシデントの解決が早期化される、関連チームを早期に巻き込み、コミュニケーションがスムーズになる。
- GKE のケーススタディ：まずは何よりも症状の緩和。根本原因の特定はその後で良い。
  - インシデントのインパクト評価→インパクトを緩和→インシデントの根本原因を分析→インシデント終了後、原因を修復し、ポストモーテムを作成
- 影響範囲が分からない場合は躊躇せず関係チームにエスカレーションして良さそう
- PagerDuty におけるインシデント対応のプロセス：https://response.pagerduty.com/
- 過去のインシデントをステージングあたりで再現して対応訓練してみたい。インシデント対応手順の改善とかも洗い出せそう
- インシデント対応の期待の共通化：インシデント中に委譲とエスカレーションができることの周知、緩和対応の優先、IC・CL・OL の役割定義
- インシデント対応の準備：コミュニケーションツールの確定、情報流通のためのフォーマットの整備、連絡先のリストの準備、インシデント発令基準の確立

### １０章：ポストモーテムの文化：失敗からの学び

- アクションアイテムには担当者を紐つける
- 感想：執筆したポストモーテムのレビューとか実施した方が良いんだろうな
  - アクションアイテムにJiraチケットと担当者、適切な優先度が割り当てられているか、コンテクストが含まれているか、非生産的な名指しや表現がないか、予防のためにできるアラートなどはあるか、あたり？
- ポストモーテムごとに用語集まで作るのは大変なので閲覧する規模に応じて取捨選択して良さそう。ただしレビューで用語のチェックはやって良さそう
- 優れたポストモーテム：明確な表現、具体的なアクションアイテム、非難がない、詳細な説明、即時性のある執筆、簡潔さ
- Blameless なコミュニケーションや表現ができることは一種のスキルに思える
- 最も多くのポストモーテムアクションアイテムをクローズした SRE（メンバー）を報奨するの良さそう。キックオフや DRAWER Value とかで支持してほしい
- ポストモーテムの勉強・振り返り会はやってみたい
- 週次など定期的な障害やインシデントのレポートもやってみたい。
- [Postmortem Checklist](https://docs.google.com/document/d/1iaEgF0ICSmKKLG3_BT5VnK80gfOenhhmxVnnUcNSQBE/edit?usp=sharing)
- ポストモーテムのアクションアイテムのモニタリング欲しい。Jira、Confluenceでうまく連携できないだろうか

### １１章：負荷の管理

### １２章：非抽象的な大規模システム設計の紹介

### １３章：データ処理パイプライン

- パイプラインのデータの新鮮さに関する一般的な SLO の形式：X ％のデータが Y 秒で処理される、最も古いデータが Y 以降、パイプラインのジョブが Y 秒以内に成功して終了する
- パイプラインに一連のステージがある場合でも、顧客が気にするのは全てのステージのまとまりに対する SLO だけ
- 一方で、パイプラインの効率性やリソースの利用情報は個々のステージ毎に計測すべき。これによってシステムの動作や改善対象を的確に把握できる
- Google では各コンポーネントとステップで生じる変換を示すシステム図を描くように推奨しており、モニタリングやデバッグ情報へのリンクを入れている
- アラートに対しては、状況把握や回復手順を記載したプレイブックのエントリを用意すると良い
- カナリアやステージング環境での検証は自動化するのに相応しいタスクと言える
- ホットスポットを防止するには、個々のレコードなどの粒度でデータをブロックしたり、リソースを過剰に消費しているタスクを分割したりすることが検討できる
- データ処理パイプラインの機能特性の例：レイテンシー、データの正確性、高可用性、MTTR、MTTD など
- パイプライン成熟度マトリクス：耐障害性、スケーラビリティ、モニタリングとデバッギング、透明性と実装の容易さ、ユニット及び結合テストそれぞれについて、成熟度（混乱→機能→継続的改善）のマトリクスを評価し、改善が必要な部分を把握する。
- パイプラインにおける潜在的な障害の形態：データの遅延（→直近のパイプラインの実行状態やログファイル、データフロー図へのリンクがあると有用）、データの破損（→適切なアラート、影響拡散のブロック、データリストアの仕組みが有用）
- 潜在的な障害の原因：パイプラインの依存対象、パイプラインアプリケーションまたは設定、予想外のリソース消費の増大、リージョンレベルの障害
- Spotify のケーススタディ、データジョブとイベント配信システムのインターフェースを配信別バケットに統一しているのスマートに感じる
- イベント配信システムの SLO を定義して運用することは、設計と開発、パフォーマンス問題の特定、顧客の期待の設定などの点で有益となっている
- イベント配信システムの SLO：適時性（配信時バケットのクローズの遅延）、スキュー性（イベントと配信時刻の割り当ての正確さ）、完全性（システムへの公開に成功したイベントのうち、配信されたものの割合？）
- 優れた顧客体験のためのドキュメンテーション：ドキュメンテーションの質問もプロダクトそのものに対する質問も同列に対処される

### １４章：設定の設計とベストプラクティス

- システムの３つのコンポーネント：ソフトウェア、システムの動作の対象となるデータセット、システムの設定
- 設定の望ましい方向：大量の調整可能な事項から離れ、シンプルさに向かう。→容易で幅広い採用と、内部的なユーザーサポートのコスト低下につながる
- ユーザー中心で設定を構築する際は、設定に対応する質問は少なく、ユーザーの要求に近いものであるべき。ユーザーが高レベルな目標を述べるなら、システムは時間とともに進化して、それらのゴールの実現方法を改善していける
- 複雑な設定を必要とするユーザーが一部にとどまらないなら、最大公約数的なユースケースを特定できていない可能性がある。その場合はシステムにおけるプロダクトの前提を見直し、追加のユーザー調査などが必要となる。
- 設定と結果データの分離や変更データの追跡は IaC と Git 管理を運用していると自然に実現されていそう。ただしシンプルさ（ユーザー目線で優先度の高いデフォルト設定とその他のオプション設定の適切な分離）を提供できているかは別。
- 安全な設定変更のための３つの主要な属性：徐々にデプロイ、危険だとわかったらロールバック、運用者の制御逸脱につながると判断された際の自動ロールバック

### １５章：設定の詳細

- 設定のレプリケーショントイル：似たような設定によるインフラを複数作る際に、重要な違いが無関係の重複した違いに埋もれてしまい、運用負荷が高くなってしまう事象。大規模なシステムの他、マイクロサービスアーキテクチャでも起こり得る。
- レプリケーショントイルの削減：複製を減らすための自動化が考えられる
- 効率的な設定システムのための要件：設定ファイルの管理ツールによる設定の健全性、エンジニアの自信、生産性のサポート。ロールバックや再現性に関する密閉性。設定とデータの分離。
- 設定のシステム化における落とし穴：設定とプログラミング言語の混同、アドホックな機能の設計、過剰なドメイン最適化、設定評価時の副作用の混入、汎用スクリプト言語の利用による実装の重量化
  - Jsonnet：https://jsonnet.org/learning/tutorial.html
- Kubernetes のケーススタディ：K8s 設定のユーザーインターフェースである YAML は簡潔な構文を持っているが、レプリケーショントイルは依然として発生しやすい。これに対して例えば Jsonnet によるテンプレート化を導入することで、プログラミング言語のモジュール化と似たメリットが得られる。
- 最近は Terraform 設定のテストもできそう：[Terraform 1.6 で追加されそうな terraform test コマンドを試してみる](https://zenn.dev/kou_pg_0131/articles/tf-1_6_alpha-test-command)

### １６章：カナリアリリース

## 第３部：プロセス

### １７章：過負荷の特定と回復

### １８章：SRE のエンゲージメントモデル

### １９章：SRE：壁の向こうへの到達

### ２０章：SRE チームのライフサイクル

### ２１章：SRE における IT 変更管理

## まとめ

